[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Longitudinal Analysis for Surveillance",
    "section": "",
    "text": "Longitudinal Analysis for Surveillance\nThis course teaches students to run “normal regressions” in situations where the data structure would ordinarily prohibit you from running regression models. These situations mostly pertain to clusters of correlated data.\nWhen dealing with longitudinal data, there are two kinds of analyses that can be performed:"
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Longitudinal Analysis for Surveillance",
    "section": "License",
    "text": "License\n\nThis work, as a whole, is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.\nThe code contained in this book is simultaneously available under the MIT license."
  },
  {
    "objectID": "qmd/100-reference.html#introduction",
    "href": "qmd/100-reference.html#introduction",
    "title": "1  Reference",
    "section": "1.1 Introduction",
    "text": "1.1 Introduction\nThere are two important definitions in this course:\n\nPanel data\nAutocorrelation\n\nPanel data is a set of data with measurements repeated at equally spaced points. For example, weight data recorded every day, or every week, or every year would be considered panel data. A person who records three weight measurements randomly in 2018 would not be considered panel data.\nWhen you have panel data, autocorrelation is the correlation between subsequent observations. For example, if you have daily observations, then the 1 day autocorrelation is the correlation between observations 1 day apart, and likewise the 2 day autocorrelation is the correlation between observations 2 days apart.\nIn this course we will consider 5 scenarios where we have multiple observations for each geographical area:\n\nPanel data: One geographical area, no autocorrelation\nPanel data: One geographical area, with autocorrelation\nNot panel data: Multiple geographical areas\nPanel data: Multiple geographical areas, no autocorrelation\nPanel data: Multiple geographical areas, with autocorrelation\n\nNote, the following scenario can be covered by standard regression models:\n\nMultiple geographical areas, one time point/observation per geographical area"
  },
  {
    "objectID": "qmd/100-reference.html#method-summary",
    "href": "qmd/100-reference.html#method-summary",
    "title": "1  Reference",
    "section": "1.2 Method summary",
    "text": "1.2 Method summary\n\n1.2.1 Panel data: One geographical area, no autocorrelation\n// STATA CODE\nglm y yearminus2000 dailyrainfall cos365 sin365, family(poisson)\n\n# R CODE\nfit1 <- glm(y~yearMinus2000 + dailyrainfall + sin365 + cos365, data=d, family=poisson())\nresiduals(fit1, type = \"response\")\n\n\n\n1.2.2 Panel data: One geographical area, with autocorrelation\n// STATA CODE\nglm y yearminus2000 cos365 sin365, family(poisson) vce(robust)\n\n# R CODE\nfit <- MASS::glmmPQL(y~yearMinus2000+sin365 + cos365, random = ~ 1 | ID,\n                family = poisson, data = d,\n                correlation=nlme::corAR1(form=~dayOfSeries|ID))\nr <- residuals(fit1, type = \"normalized\")\npacf(r)\n\n\n\n1.2.3 Not panel data: Multiple geographical areas\n// STATA CODE\nmeglm y x yearMinus2000 || fylke:, family(poisson)\n\n# R CODE\nfit <- lme4::glmer(y~x + yearMinus2000 + (1|fylke),data=d,family=poisson())\n\n\n\n1.2.4 Panel data: Multiple geographical areas, no autocorrelation\n// STATA CODE\nmeglm y yearminus2000 cos365 sin365 || fylke:, family(poisson)\n\n# R CODE\nfit <- MASS::glmmPQL(y~yearMinus2000+sin365 + cos365, random = ~ 1 | fylke,\n                family = poisson, data = d)\nr <- residuals(fit1, type = \"normalized\")\npacf(r)\n\n\n\n1.2.5 Panel data: Multiple geographical areas, with autocorrelation\n// STATA CODE\nmeglm y yearminus2000 cos365 sin365 || fylke:, family(poisson) vce(robust)\n\n# R CODE\nfit <- MASS::glmmPQL(y~yearMinus2000+sin365 + cos365, random = ~ 1 | fylke,\n                family = poisson, data = d,\n                correlation=nlme::corAR1(form=~dayOfSeries|fylke))\nr <- residuals(fit1, type = \"normalized\")\npacf(r)"
  },
  {
    "objectID": "qmd/100-reference.html#identifying-your-scenario",
    "href": "qmd/100-reference.html#identifying-your-scenario",
    "title": "1  Reference",
    "section": "1.3 Identifying your scenario",
    "text": "1.3 Identifying your scenario\n\n1.3.1 Step 1: Do you have panel data?\nThis step should be fairly simple. If your data has equally spaced time intervals between them, you have panel data.\n\n\n1.3.2 Step 2: Do you have multiple geographical areas?\nAgain, fairly simple, just look at your data.\n\n\n1.3.3 Step 3: Do you have autocorrelation?\nFirstly, you must run a model pretending that you do not have autocorrelation.\nYou then inspect the residuals from the model and see if autocorrelation exists. This is done with two statistical procedures: pacf (for autoregressive models, the most common type of autocorrelation), and acf (for moving average models, a less common type of autocorrelation).\n\n\n\n1.3.4 AR(1) data\n\ny <- round(as.numeric(arima.sim(model=list(\"ar\"=c(0.5)), rand.gen = rnorm, n=1000)))\n\nWith autoregressive data, a pacf plot contains a number of sharp significant lines, indicating how many subsequent observations have autocorrelation. i.e. if one line is significant, it means that each observation is only correlated with its preceeding observation (AR(1)). If two lines are significant, it means that each observation is correlated with its two preceeding observations (AR(2)). The following plot represents AR(1) data.\n\npacf(y)\n\n\n\n\n\nWith autoregressive data, an acf plot contains a number of decreasing lines. The following acf plot represents some sort of AR data. Note that the acf plot displays lag 0 (which is pointless and can be ignored), while the pacf plot does not.\n\nacf(y)\n\n\n\n\n\n\n\n1.3.5 AR(2) data\n\ny <- round(as.numeric(arima.sim(model=list(\"ar\"=c(0.5,0.4)), rand.gen = rnorm, n=1000)))\n\nThe following pacf plot represents AR(2) data. This means that each observation is correlated with its two preceeding observations (AR(2)).\n\npacf(y)\n\n\n\n\n\nThe following acf plot represents some sort of AR data:\n\nacf(y)\n\n\n\n\n\n\n\n1.3.6 MA(1) data\n\ny <- round(as.numeric(arima.sim(model=list(\"ma\"=c(0.9)), rand.gen = rnorm, n=1000)))\n\nWith moving average data, a pacf plot contains a number of decreasing lines. The following pacf plot represents some sort of MA data.:\n\npacf(y)\n\n\n\n\n\nWith moving average data, an acf plot contains a number of sharp significant lines, demarking how many subsequent observations have autocorrelation. i.e. if one line is significant, it means that each observation is only correlated with its preceeding observation. If two lines are significant, it means that each observation is correlated with its two preceeding observations. The following plot represents MA(1) data. Note that the acf plot displays lag 0 (which is pointless and can be ignored), while the pacf plot does not.\n\nacf(y)\n\n\n\n\n\n\n\n1.3.7 MA(2) data\n\ny <- round(as.numeric(arima.sim(model=list(\"ma\"=c(0.9,0.6)), rand.gen = rnorm, n=1000)))\n\nThe following pacf plot represents some sort of MA data.\n\npacf(y)\n\n\n\n\n\nThe following acf plot represents MA(2) data. This means that each observation is correlated with its two preceeding observations.\n\nacf(y)"
  },
  {
    "objectID": "qmd/200-one-area-no-autocorrelation.html#aim",
    "href": "qmd/200-one-area-no-autocorrelation.html#aim",
    "title": "2  Panel data: One area without autocorrelation",
    "section": "2.1 Aim",
    "text": "2.1 Aim\nWe are given a dataset containing daily counts of diseases from one geographical area. We want to identify:\n\nDoes seasonality exist?\nIf seasonality exists, when are the high/low seasons?\nIs there a general yearly trend (i.e. increasing or decreasing from year to year?)\nIs daily rainfall associated with the number of cases?"
  },
  {
    "objectID": "qmd/200-one-area-no-autocorrelation.html#creating-the-data",
    "href": "qmd/200-one-area-no-autocorrelation.html#creating-the-data",
    "title": "2  Panel data: One area without autocorrelation",
    "section": "2.2 Creating the data",
    "text": "2.2 Creating the data\nThe data for this chapter is available at: https://www.csids.no/longitudinal-analysis-for-surveillance/data/chapter_2.csv\n\n# R CODE\n\nlibrary(data.table)\nlibrary(ggplot2)\nset.seed(4)\n\nAMPLITUDE <- 1.5\nSEASONAL_HORIZONTAL_SHIFT <- 20\n\nd <- data.table(date=seq.Date(\n  from=as.Date(\"2000-01-01\"),\n  to=as.Date(\"2018-12-31\"),\n  by=1))\nd[,year:=as.numeric(format.Date(date,\"%G\"))]\nd[,week:=as.numeric(format.Date(date,\"%V\"))]\nd[,month:=as.numeric(format.Date(date,\"%m\"))]\nd[,yearMinus2000:=year-2000]\nd[,dailyrainfall:=runif(.N, min=0, max=10)]\n\nd[,dayOfYear:=as.numeric(format.Date(date,\"%j\"))]\nd[,seasonalEffect:=sin(2*pi*(dayOfYear-SEASONAL_HORIZONTAL_SHIFT)/365)]\nd[,mu := exp(0.1 + yearMinus2000*0.1 + seasonalEffect*AMPLITUDE)]\nd[,y:=rpois(.N,mu)]"
  },
  {
    "objectID": "qmd/200-one-area-no-autocorrelation.html#true-data",
    "href": "qmd/200-one-area-no-autocorrelation.html#true-data",
    "title": "2  Panel data: One area without autocorrelation",
    "section": "2.3 True data",
    "text": "2.3 True data\nHere we show the true data, and note that there is an increasing annual trend (the data gets higher as time goes on) and there is a seasonal pattern (one peak/trough per year)\n\nq <- ggplot(d,aes(x=date))\nq <- q + geom_point(mapping=aes(y=y))\nq <- q + geom_line(mapping=aes(y=mu),colour=\"red\")\nq"
  },
  {
    "objectID": "qmd/200-one-area-no-autocorrelation.html#investigation",
    "href": "qmd/200-one-area-no-autocorrelation.html#investigation",
    "title": "2  Panel data: One area without autocorrelation",
    "section": "2.4 Investigation",
    "text": "2.4 Investigation\nPretending we have no prior knowledge of our dataset, we display the data for few years and see a clear seasonal trend\n\nq <- ggplot(d[year %in% c(2005:2010)],aes(x=dayOfYear,y=y))\nq <- q + facet_wrap(~year)\nq <- q + geom_point()\nq <- q + stat_smooth(colour=\"red\")\nq\n\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'"
  },
  {
    "objectID": "qmd/200-one-area-no-autocorrelation.html#seasonality",
    "href": "qmd/200-one-area-no-autocorrelation.html#seasonality",
    "title": "2  Panel data: One area without autocorrelation",
    "section": "2.5 Seasonality",
    "text": "2.5 Seasonality\nIf we want to investigate the seasonality of our data, and identify when are the peaks and troughs, we have a few ways to approach this.\nNon-parametric approaches are flexible and easy to implement, but they can lack power and be hard to interpret:\n\nCreate a categorical variable for the seasons (e.g. spring, summer, autumn, winter) and include this in the regression model\nCreate a categorical variable for the months (e.g. Jan, Feb, …, Dec) and include this in the regression model\n\nParametric approaches are more powerful but require more effort:\n\nIdentify the periodicity of the seasonality (how many days between peaks?)\nUsing trigonometry, transform day of year into variables that appropriately model the observed periodicity\nObtain coefficient estimates\nBack-transform these estimates into human-understandable values (day of peak, day of trough)\n\nThe non-parametric approaches are simple and we will therefore not cover them in this course. We will briefly examine the parametric approach.\nNOTE: You don’t always have to investigate seasonality! It depends entirely on what the purpose of your analysis is!\n\nThe Lomb-Scargle Periodogram shows a clear seasonality with a period of 365 days.\n// STATA CODE STARTS\ninsheet using \"chapter_3.csv\", clear\n\nsort date\ngen time=_n\ntsset time, daily\n\nwntestb y\n\ncumsp y, gen(cumulative_spec_dist)\ngen period=_N/_n\n\nbrowse cumulative_spec_dist period\n// STATA CODE ENDS\n\n# R CODE \nlomb::lsp(d$y,from=100,to=500,ofac=1,type=\"period\")\n\n\n\n\n\nWe then generate two new variables cos365 and sin365 and perform a likelihood ratio test to see if they are significant or not. This is done with two simple poisson regressions.\nWhen we do not have autocorrelation, we can use the glm function in R and in STATA. Note that it is very important to specify the family (as this is how we differentiate between linear/logistic/poisson regressions).\n// STATA CODE STARTS\ngen cos365=cos(dayofyear*2*_pi/365)\ngen sin365=sin(dayofyear*2*_pi/365)\n\nglm y yearminus2000 dailyrainfall, family(poisson)\nestimates store m1\nglm y yearminus2000 dailyrainfall cos365 sin365, family(poisson)\nestimates store m2\n\npredict resid, anscombe\n\nlrtest m1 m2\n// STATA CODE ENDS\n\n# R CODE\nd[,cos365:=cos(dayOfYear*2*pi/365)]\nd[,sin365:=sin(dayOfYear*2*pi/365)]\n\nfit0 <- glm(y~yearMinus2000 + dailyrainfall, data=d, family=poisson())\nfit1 <- glm(y~yearMinus2000 + dailyrainfall + sin365 + cos365, data=d, family=poisson())\n\nprint(lmtest::lrtest(fit0, fit1))\n\nLikelihood ratio test\n\nModel 1: y ~ yearMinus2000 + dailyrainfall\nModel 2: y ~ yearMinus2000 + dailyrainfall + sin365 + cos365\n  #Df LogLik Df Chisq Pr(>Chisq)    \n1   3 -26904                        \n2   5 -12892  2 28024  < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWe see that the likelihood ratio test for sin365 and cos365 was significant, meaning that there is significant seasonality with a 365 day periodicity in our data (which we already strongly suspected due to the periodogram).\n\nWe can now run/look at the results of our main regression.\n\nprint(summary(fit1))\n\n\nCall:\nglm(formula = y ~ yearMinus2000 + dailyrainfall + sin365 + cos365, \n    family = poisson(), data = d)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-4.0676  -0.9229  -0.1170   0.5861   3.4103  \n\nCoefficients:\n                Estimate Std. Error z value Pr(>|z|)    \n(Intercept)    0.0887436  0.0176742   5.021 5.14e-07 ***\nyearMinus2000  0.1016117  0.0010525  96.539  < 2e-16 ***\ndailyrainfall  0.0002287  0.0018476   0.124    0.901    \nsin365         1.3972586  0.0103200 135.393  < 2e-16 ***\ncos365        -0.5035265  0.0086308 -58.341  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 45536.8  on 6939  degrees of freedom\nResidual deviance:  7328.5  on 6935  degrees of freedom\nAIC: 25794\n\nNumber of Fisher Scoring iterations: 5\n\n\nWe also see that the (significant!) coefficient for year is 0.1 which means that for each additional year, the outcome increases by exp(0.1)=1.11. We also see that the coefficient for dailyrainfall was not significant, which means that we did not find a significant association between the outcome and dailyrainfall.\nNOTE: See that this is basically the same as a normal regression.\n\nThrough the likelihood ratio test we saw a clear significant seasonal effect. We can now use trigonometry to back-calculate the amplitude and location of peak/troughs from the cos365 and sin365 estimates:\n\nb1 <- 1.428417 # sin coefficient\nb2 <- -0.512912 # cos coefficient\namplitude <- sqrt(b1^2 + b2^2)\np <- atan(b1/b2) * 365/2/pi\nif (p > 0) {\n    peak <- p\n    trough <- p + 365/2\n} else {\n    peak <- p + 365/2\n    trough <- p + 365\n}\nif (b1 < 0) {\n    g <- peak\n    peak <- trough\n    trough <- g\n}\nprint(sprintf(\"amplitude is estimated as %s, peak is estimated as %s, trough is estimated as %s\",round(amplitude,2),round(peak),round(trough)))\n\n[1] \"amplitude is estimated as 1.52, peak is estimated as 111, trough is estimated as 294\"\n\nprint(sprintf(\"true values are: amplitude: %s, peak: %s, trough: %s\",round(AMPLITUDE,2),round(365/4+SEASONAL_HORIZONTAL_SHIFT),round(3*365/4+SEASONAL_HORIZONTAL_SHIFT)))\n\n[1] \"true values are: amplitude: 1.5, peak: 111, trough: 294\"\n\n\nNOTE: An amplitude of 1.5 means that when comparing the average time of year to the peak, the peak is expected to be exp(1.5)=4.5 times higher than average. We take the exponential because we have run a poisson regression (so think incident rate ratio).\n\nWe now investigate our residuals to determine if we have a good fit:\n\nd[,residuals:=residuals(fit1, type = \"response\")]\nd[,predicted:=predict(fit1, type = \"response\")]\nq <- ggplot(d,aes(x=predicted,y=residuals))\nq <- q + geom_point()\nq <- q + stat_smooth(colour=\"red\")\nq\n\n`geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\nWe check the pacf of the residuals to ensure that it is not AR. If we observe AR in our residuals, then this model was not appropriate and we need to use a different model.\n// STATA CODE STARTS\npac resid\n// STATA CODE ENDS\n\n# R CODE\n# this is for AR\npacf(d$residuals)\n\n\n\n\n\nWe check the acf of the residuals to ensure that it is not MA. If we observe MA in our residuals, then this model was not appropriate and we need to use a different model.\n// STATA CODE STARTS\nac resid\n// STATA CODE ENDS\n\n# R CODE\n# this is for MA\nacf(d$residuals)"
  },
  {
    "objectID": "qmd/300-one-area-with-autocorrelation.html#aim",
    "href": "qmd/300-one-area-with-autocorrelation.html#aim",
    "title": "3  Panel data: One area with autocorrelation",
    "section": "3.1 Aim",
    "text": "3.1 Aim\nWe are given a dataset containing daily counts of diseases from one geographical area. We want to identify:\n\nDoes seasonality exist?\nIf seasonality exists, when are the high/low seasons?\nIs there a general yearly trend (i.e. increasing or decreasing from year to year?)\n\n(We remove the question about rainfall in order to simplify and streamline the exercise)"
  },
  {
    "objectID": "qmd/300-one-area-with-autocorrelation.html#creating-the-data",
    "href": "qmd/300-one-area-with-autocorrelation.html#creating-the-data",
    "title": "3  Panel data: One area with autocorrelation",
    "section": "3.2 Creating the data",
    "text": "3.2 Creating the data\nThe data for this chapter is available at: https://www.csids.no/longitudinal-analysis-for-surveillance/data/chapter_3.csv\n\nlibrary(data.table)\nlibrary(ggplot2)\nset.seed(4)\n\nAMPLITUDE <- 1.5\nSEASONAL_HORIZONTAL_SHIFT <- 20\n\nd <- data.table(date=seq.Date(\n  from=as.Date(\"2000-01-01\"),\n  to=as.Date(\"2018-12-31\"),\n  by=1))\nd[,year:=as.numeric(format.Date(date,\"%G\"))]\nd[,week:=as.numeric(format.Date(date,\"%V\"))]\nd[,month:=as.numeric(format.Date(date,\"%m\"))]\nd[,yearMinus2000:=year-2000]\nd[,dayOfSeries:=1:.N]\n\nd[,dayOfYear:=as.numeric(format.Date(date,\"%j\"))]\nd[,seasonalEffect:=sin(2*pi*(dayOfYear-SEASONAL_HORIZONTAL_SHIFT)/365)]\nd[,mu := exp(0.1 + yearMinus2000*0.1 + seasonalEffect*AMPLITUDE)]\nd[,y:=rpois(.N,mu)]\nd[,y:=round(as.numeric(arima.sim(model=list(\"ar\"=c(0.5)), rand.gen = rpois, n=nrow(d), lambda=mu)))]"
  },
  {
    "objectID": "qmd/300-one-area-with-autocorrelation.html#investigation",
    "href": "qmd/300-one-area-with-autocorrelation.html#investigation",
    "title": "3  Panel data: One area with autocorrelation",
    "section": "3.3 Investigation",
    "text": "3.3 Investigation\nWe display the data for few years and see a clear seasonal trend\n\nq <- ggplot(d[year %in% c(2005:2010)],aes(x=dayOfYear,y=y))\nq <- q + facet_wrap(~year)\nq <- q + geom_point()\nq <- q + stat_smooth(colour=\"red\")\nq\n\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n\n\n\n\n\n\nThe Lomb-Scargle Periodogram shows a clear seasonality with a period of 365 days\n// STATA CODE STARTS\ninsheet using \"chapter_4.csv\", clear\n\nsort date\ngen time=_n\ntsset time, daily\n\nwntestb y\n\ncumsp y, gen(cumulative_spec_dist)\ngen period=_N/_n\n\nbrowse cumulative_spec_dist period\n// STATA CODE ENDS\n\n# R CODE\nlomb::lsp(d$y,from=50,to=500,ofac=1,type=\"period\")"
  },
  {
    "objectID": "qmd/300-one-area-with-autocorrelation.html#regressions",
    "href": "qmd/300-one-area-with-autocorrelation.html#regressions",
    "title": "3  Panel data: One area with autocorrelation",
    "section": "3.4 Regressions",
    "text": "3.4 Regressions\nWe then generate two new variables cos365 and sin365 and perform a likelihood ratio test to see if they are significant or not. This is done with two simple poisson regressions.\n// STATA CODE STARTS\ngen cos365=cos(dayofyear*2*_pi/365)\ngen sin365=sin(dayofyear*2*_pi/365)\n\nglm y yearminus2000, family(poisson)\nestimates store m1\nglm y yearminus2000 cos365 sin365, family(poisson)\nestimates store m2\n\npredict resid, anscombe\n\nlrtest m1 m2\n// STATA CODE ENDS\n\n# R CODE\nd[,cos365:=cos(dayOfYear*2*pi/365)]\nd[,sin365:=sin(dayOfYear*2*pi/365)]\n\nfit0 <- glm(y~yearMinus2000, data=d, family=poisson())\nfit1 <- glm(y~yearMinus2000+sin365 + cos365, data=d, family=poisson())\n\nprint(lmtest::lrtest(fit0, fit1))\n\nLikelihood ratio test\n\nModel 1: y ~ yearMinus2000\nModel 2: y ~ yearMinus2000 + sin365 + cos365\n  #Df LogLik Df Chisq Pr(>Chisq)    \n1   2 -43124                        \n2   4 -14542  2 57163  < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWe see that the likelihood ratio test for sin365 and cos365 was significant, meaning that there is significant seasonality with a 365 day periodicity in our data (which we already strongly suspected due to the periodogram).\n\nWe can now run/look at the results of our main regression.\n\nprint(summary(fit1))\n\n\nCall:\nglm(formula = y ~ yearMinus2000 + sin365 + cos365, family = poisson(), \n    data = d)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.6774  -0.6738  -0.0503   0.4920   3.5820  \n\nCoefficients:\n                Estimate Std. Error z value Pr(>|z|)    \n(Intercept)    0.7981246  0.0105300   75.80   <2e-16 ***\nyearMinus2000  0.0991480  0.0007416  133.70   <2e-16 ***\nsin365         1.4074818  0.0073418  191.71   <2e-16 ***\ncos365        -0.5390314  0.0061513  -87.63   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 81832.6  on 6939  degrees of freedom\nResidual deviance:  5217.8  on 6936  degrees of freedom\nAIC: 29093\n\nNumber of Fisher Scoring iterations: 4\n\n\nWe also see that the coefficient for year is 0.1 which means that for each additional year, the outcome increases by exp(0.1)=1.11."
  },
  {
    "objectID": "qmd/300-one-area-with-autocorrelation.html#residual-analysis",
    "href": "qmd/300-one-area-with-autocorrelation.html#residual-analysis",
    "title": "3  Panel data: One area with autocorrelation",
    "section": "3.5 Residual analysis",
    "text": "3.5 Residual analysis\n\nd[,residuals:=residuals(fit1, type = \"response\")]\nd[,predicted:=predict(fit1, type = \"response\")]\n\nWe can see a clear AR(1) pattern in our residuals.\n// STATA CODE STARTS\npac resid\n// STATA CODE ENDS\n\n# R CODE\n# this is for AR\npacf(d$residuals)\n\n\n\n\n\nAnd again we see some sort of AR pattern in our residuals.\n// STATA CODE STARTS\nac resid\n// STATA CODE ENDS\n\n# R CODE\n# this is for MA\nacf(d$residuals)\n\n\n\n\nThis means our model is bad, we have autocorrelation. We now need to change our model to account for this AR(1) autocorrelation!"
  },
  {
    "objectID": "qmd/300-one-area-with-autocorrelation.html#r-only-regression-with-ar1-correlation-in-residuals",
    "href": "qmd/300-one-area-with-autocorrelation.html#r-only-regression-with-ar1-correlation-in-residuals",
    "title": "3  Panel data: One area with autocorrelation",
    "section": "3.6 (R ONLY) Regression with AR(1) correlation in residuals",
    "text": "3.6 (R ONLY) Regression with AR(1) correlation in residuals\nFirst we create an id variable. This generally corresponds to geographical locations, or people. In this case, we only have one geographical location, so our id for all observations is 1. This lets the computer know that all data belongs to the same group.\nWhen we have autocorrelation in the residuals, we can use the MASS::glmPQL function in R.\n\nd[,ID:=1]\n# this is for MA\nfit <- MASS::glmmPQL(y~yearMinus2000+sin365 + cos365, random = ~ 1 | ID,\n                family = poisson, data = d,\n                correlation=nlme::corAR1(form=~dayOfSeries|ID))\n\niteration 1\n\nsummary(fit)\n\nLinear mixed-effects model fit by maximum likelihood\n  Data: d \n  AIC BIC logLik\n   NA  NA     NA\n\nRandom effects:\n Formula: ~1 | ID\n         (Intercept) Residual\nStdDev: 1.149087e-05 0.841689\n\nCorrelation Structure: AR(1)\n Formula: ~dayOfSeries | ID \n Parameter estimate(s):\n      Phi \n0.4926123 \nVariance function:\n Structure: fixed weights\n Formula: ~invwt \nFixed effects:  y ~ yearMinus2000 + sin365 + cos365 \n                   Value   Std.Error   DF   t-value p-value\n(Intercept)    0.7980540 0.015203158 6936  52.49265       0\nyearMinus2000  0.0991582 0.001070583 6936  92.62077       0\nsin365         1.4074339 0.010596650 6936 132.81876       0\ncos365        -0.5389807 0.008876448 6936 -60.72031       0\n Correlation: \n              (Intr) yM2000 sin365\nyearMinus2000 -0.832              \nsin365        -0.409  0.000       \ncos365         0.186  0.000 -0.158\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-2.89886750 -0.75775061 -0.05982255  0.60730689  6.49964489 \n\nNumber of Observations: 6940\nNumber of Groups: 1 \n\n\n\nWe can see that the residuals no longer display any signs of autocorrelation.\n\npacf(residuals(fit, type = \"normalized\")) # this is for AR\n\n\n\n\n\nWe can see that the residuals no longer display any signs of autocorrelation.\n\nacf(residuals(fit, type = \"normalized\")) # this is for MA\n\n\n\n\n\nWe also obtain the same estimates that we did in the last chapter.\n\nb1 <- 1.3936185 # sin coefficient\nb2 <- -0.5233866 # cos coefficient\namplitude <- sqrt(b1^2 + b2^2)\np <- atan(b1/b2) * 365/2/pi\nif (p > 0) {\n    peak <- p\n    trough <- p + 365/2\n} else {\n    peak <- p + 365/2\n    trough <- p + 365\n}\nif (b1 < 0) {\n    g <- peak\n    peak <- trough\n    trough <- g\n}\nprint(sprintf(\"amplitude is estimated as %s, peak is estimated as %s, trough is estimated as %s\",round(amplitude,2),round(peak),round(trough)))\n\n[1] \"amplitude is estimated as 1.49, peak is estimated as 112, trough is estimated as 295\"\n\nprint(sprintf(\"true values are: amplitude: %s, peak: %s, trough: %s\",round(AMPLITUDE,2),round(365/4+SEASONAL_HORIZONTAL_SHIFT),round(3*365/4+SEASONAL_HORIZONTAL_SHIFT)))\n\n[1] \"true values are: amplitude: 1.5, peak: 111, trough: 294\""
  },
  {
    "objectID": "qmd/300-one-area-with-autocorrelation.html#stata-only-regression-with-robust-standard-errors",
    "href": "qmd/300-one-area-with-autocorrelation.html#stata-only-regression-with-robust-standard-errors",
    "title": "3  Panel data: One area with autocorrelation",
    "section": "3.7 (STATA ONLY) Regression with robust standard errors",
    "text": "3.7 (STATA ONLY) Regression with robust standard errors\nIn STATA it is not possible to explicitly model autocorrelation in the residuals (with the exception of linear regression). Since most of our work deals with logistic and poisson regressions, we will be focusing on modelling strategies that work with all kinds of regressions.\nThe STATA approach to autocorrelation is to estimate more robust standard errors. That is, STATA makes the standard errors larger to account for the model mispecification. This is done through the vce(robust) option.\n// STATA CODE STARTS\nglm y yearminus2000 cos365 sin365, family(poisson) vce(robust)\n// STATA CODE ENDS"
  },
  {
    "objectID": "qmd/400-multiple-areas-no-panel-data.html#aim",
    "href": "qmd/400-multiple-areas-no-panel-data.html#aim",
    "title": "4  Not panel data: Multiple areas",
    "section": "4.1 Aim",
    "text": "4.1 Aim\nWe are given a dataset containing counts of diseases from multiple geographical areas. We want to identify:\n\nIs there a general yearly trend (i.e. increasing or decreasing from year to year?)\nIs variable x associated with the outcome?"
  },
  {
    "objectID": "qmd/400-multiple-areas-no-panel-data.html#creating-the-data",
    "href": "qmd/400-multiple-areas-no-panel-data.html#creating-the-data",
    "title": "4  Not panel data: Multiple areas",
    "section": "4.2 Creating the data",
    "text": "4.2 Creating the data\nThe data for this chapter is available at: https://www.csids.no/longitudinal-analysis-for-surveillance/data/chapter_4.csv\n\nlibrary(data.table)\nlibrary(lme4)\n\nLoading required package: Matrix\n\nset.seed(4)\n\nfylkeIntercepts <- data.table(fylke=1:20,fylkeIntercepts=rnorm(20))\n\nd <- data.table(fylke=rep(1:20,each=100))\nd <- merge(d,fylkeIntercepts,by=\"fylke\")\nd[,mainIntercept:=3]\nd[,x:=runif(.N)]\nd[,year:=sample(c(1950:2018),.N,replace=T)]\nd[,mu := exp(mainIntercept + fylkeIntercepts + 3*x)]\nd[,y:=rpois(.N,mu)]"
  },
  {
    "objectID": "qmd/400-multiple-areas-no-panel-data.html#investigating-the-data",
    "href": "qmd/400-multiple-areas-no-panel-data.html#investigating-the-data",
    "title": "4  Not panel data: Multiple areas",
    "section": "4.3 Investigating the data",
    "text": "4.3 Investigating the data\nWe can see from the data that we have 20 geographical areas (fylke) with 100 observations for each fylke, but the sampling did not happen consistently (some years have multiple measurements, other years have no measurements).\nThis means we have:\n\nmultiple geographical areas\nmultiple observations in each geographical area\nnot panel data\n\n\nprint(d)\n\n      fylke fylkeIntercepts mainIntercept          x year        mu   y\n   1:     1       0.2167549             3 0.93831909 1961 416.42739 407\n   2:     1       0.2167549             3 0.24217109 1960  51.58692  41\n   3:     1       0.2167549             3 0.56559453 1999 136.12022 132\n   4:     1       0.2167549             3 0.18089910 1963  42.92490  37\n   5:     1       0.2167549             3 0.90449929 2001 376.24959 423\n  ---                                                                  \n1996:    20      -0.2834446             3 0.89237059 1958 220.00872 230\n1997:    20      -0.2834446             3 0.80522348 1959 169.39375 173\n1998:    20      -0.2834446             3 0.59989167 1974  91.49007  95\n1999:    20      -0.2834446             3 0.04148228 1950  17.13293  19\n2000:    20      -0.2834446             3 0.77673920 1971 155.51980 164"
  },
  {
    "objectID": "qmd/400-multiple-areas-no-panel-data.html#regression",
    "href": "qmd/400-multiple-areas-no-panel-data.html#regression",
    "title": "4  Not panel data: Multiple areas",
    "section": "4.4 Regression",
    "text": "4.4 Regression\nFor this scenario, we use the lme4::glmer function in R. We need to introduce a (1|fylke) term to identify the geographical areas (i.e. clusters). In STATA we use the meglm function and introduce a || fylke: term to identify the geographical areas (i.e. clusters).\n// STATA CODE STARTS\ninsheet using \"chapter_5.csv\", clear\n\ngen yearMinus2000 = year-2000\nmeglm y x yearMinus2000 || fylke:, family(poisson)\n// STATA CODE ENDS\n\n# R CODE\nd[,yearMinus2000:=year-2000]\nsummary(fit <- lme4::glmer(y~x + yearMinus2000 + (1|fylke),data=d,family=poisson()))\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: poisson  ( log )\nFormula: y ~ x + yearMinus2000 + (1 | fylke)\n   Data: d\n\n     AIC      BIC   logLik deviance df.resid \n 15502.5  15524.9  -7747.2  15494.5     1996 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.3647 -0.6802 -0.0153  0.6681  4.3638 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n fylke  (Intercept) 0.6114   0.7819  \nNumber of obs: 2000, groups:  fylke, 20\n\nFixed effects:\n               Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   3.375e+00  1.749e-01  19.298   <2e-16 ***\nx             3.002e+00  6.000e-03 500.407   <2e-16 ***\nyearMinus2000 8.884e-05  7.270e-05   1.222    0.222    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) x     \nx           -0.024       \nyearMns2000  0.006  0.033\noptimizer (Nelder_Mead) convergence code: 0 (OK)\nModel is nearly unidentifiable: very large eigenvalue\n - Rescale variables?\nModel is nearly unidentifiable: large eigenvalue ratio\n - Rescale variables?\n\n\nYou can see that the format of the results is the same as an ordinary regression."
  },
  {
    "objectID": "qmd/500-multiple-areas-no-autocorrelation.html#aim",
    "href": "qmd/500-multiple-areas-no-autocorrelation.html#aim",
    "title": "5  Panel data: multiple areas without autocorrelation",
    "section": "5.1 Aim",
    "text": "5.1 Aim\nWe are given a dataset containing daily counts of diseases from multiple geographical areas. We want to identify:\n\nDoes seasonality exist?\nIf seasonality exists, when are the high/low seasons?\nIs there a general yearly trend (i.e. increasing or decreasing from year to year?)"
  },
  {
    "objectID": "qmd/500-multiple-areas-no-autocorrelation.html#creating-the-data",
    "href": "qmd/500-multiple-areas-no-autocorrelation.html#creating-the-data",
    "title": "5  Panel data: multiple areas without autocorrelation",
    "section": "5.2 Creating the data",
    "text": "5.2 Creating the data\nThe data for this chapter is available at: https://www.csids.no/longitudinal-analysis-for-surveillance/data/chapter_5.csv\n\nlibrary(data.table)\nlibrary(ggplot2)\nset.seed(4)\n\nAMPLITUDE <- 1.5\nSEASONAL_HORIZONTAL_SHIFT <- 20\n\nfylkeIntercepts <- data.table(fylke=1:20,fylkeIntercepts=rnorm(20))\n\nd <- data.table(date=seq.Date(\n  from=as.Date(\"2010-01-01\"),\n  to=as.Date(\"2015-12-31\"),\n  by=1))\nd[,year:=as.numeric(format.Date(date,\"%G\"))]\nd[,week:=as.numeric(format.Date(date,\"%V\"))]\nd[,month:=as.numeric(format.Date(date,\"%m\"))]\n\ntemp <- vector(\"list\",length=20)\nfor(i in 1:20){\n  temp[[i]] <- copy(d)\n  temp[[i]][,fylke:=i]\n}\nd <- rbindlist(temp)\n\nd[,yearMinus2000:=year-2000]\nd[,dayOfSeries:=1:.N]\n\nd[,dayOfYear:=as.numeric(format.Date(date,\"%j\"))]\nd[,seasonalEffect:=sin(2*pi*(dayOfYear-SEASONAL_HORIZONTAL_SHIFT)/365)]\nd[,mu := exp(0.1 + yearMinus2000*0.1 + seasonalEffect*AMPLITUDE)]\nd[,y:=rpois(.N,mu)]"
  },
  {
    "objectID": "qmd/500-multiple-areas-no-autocorrelation.html#investigation",
    "href": "qmd/500-multiple-areas-no-autocorrelation.html#investigation",
    "title": "5  Panel data: multiple areas without autocorrelation",
    "section": "5.3 Investigation",
    "text": "5.3 Investigation\nWe then drill down into a few years for fylke 1, and see a clear seasonal trend\n\nq <- ggplot(d[fylke==1],aes(x=dayOfYear,y=y))\nq <- q + facet_wrap(~year)\nq <- q + geom_point()\nq <- q + stat_smooth(colour=\"red\")\nq\n\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n\n\n\n\n\n\nThe Lomb-Scargle Periodogram shows a clear seasonality with a period of 365 days\n// STATA CODE STARTS\ninsheet using \"chapter_6.csv\", clear\n\nsort fylke date\nby fylke: gen time=_n\ntsset fylke time, daily\n\nwntestb y if fylke==1\n\ncumsp y if fylke==1, gen(cumulative_spec_dist)\nby fylke: gen period=_N/_n\n\nbrowse cumulative_spec_dist period\n// STATA CODE ENDS\n\n# RCODE\nlomb::lsp(d$y,from=100,to=500,ofac=1,type=\"period\")"
  },
  {
    "objectID": "qmd/500-multiple-areas-no-autocorrelation.html#regression",
    "href": "qmd/500-multiple-areas-no-autocorrelation.html#regression",
    "title": "5  Panel data: multiple areas without autocorrelation",
    "section": "5.4 Regression",
    "text": "5.4 Regression\nFirst we create an id variable. This generally corresponds to geographical locations, or people. In this case, we only have one geographical location, so our id for all observations is 1. This lets the computer know that all data belongs to the same group.\nWhen we have panel data with multiple areas, we use the MASS::glmPQL function in R and the meglm function in STATA. In R we identify the geographical areas with random = ~ 1 | fylke and in STATA with || fylke:.\n// STATA CODE STARTS\ngen cos365=cos(dayofyear*2*_pi/365)\ngen sin365=sin(dayofyear*2*_pi/365)\n\nmeglm y yearminus2000 || fylke:, family(poisson) iter(10)\nestimates store m1\nmeglm y yearminus2000 cos365 sin365 || fylke:, family(poisson) iter(10)\nestimates store m2\n\npredict resid, anscombe\n\nlrtest m1 m2\n// STATA CODE ENDS\n\n# R CODE\nd[,cos365:=cos(dayOfYear*2*pi/365)]\nd[,sin365:=sin(dayOfYear*2*pi/365)]\nfit0 <- MASS::glmmPQL(y~yearMinus2000, random = ~ 1 | fylke,\n                family = poisson, data = d)\n\niteration 1\n\nfit1 <- MASS::glmmPQL(y~yearMinus2000 + sin365 + cos365, random = ~ 1 | fylke,\n                family = poisson, data = d)\n\niteration 1\n\nprint(lmtest::lrtest(fit0, fit1))\n\nLikelihood ratio test\n\nModel 1: y ~ yearMinus2000\nModel 2: y ~ yearMinus2000 + sin365 + cos365\n  #Df LogLik Df Chisq Pr(>Chisq)\n1   4                           \n2   6         2                 \n\n\nWe see that the likelihood ratio test for sin365 and cos365 was significant, meaning that there is significant seasonality with a 365 day periodicity in our data (which we already strongly suspected due to the periodogram).\n\nWe can now run/look at the results of our main regression.\n\nprint(summary(fit1))\n\nLinear mixed-effects model fit by maximum likelihood\n  Data: d \n  AIC BIC logLik\n   NA  NA     NA\n\nRandom effects:\n Formula: ~1 | fylke\n         (Intercept)  Residual\nStdDev: 1.583744e-05 0.9976713\n\nVariance function:\n Structure: fixed weights\n Formula: ~invwt \nFixed effects:  y ~ yearMinus2000 + sin365 + cos365 \n                   Value   Std.Error    DF   t-value p-value\n(Intercept)    0.1122536 0.014488403 43797    7.7478       0\nyearMinus2000  0.0989047 0.001109477 43797   89.1453       0\nsin365         1.4095095 0.003695341 43797  381.4288       0\ncos365        -0.5109375 0.003083683 43797 -165.6907       0\n Correlation: \n              (Intr) yM2000 sin365\nyearMinus2000 -0.979              \nsin365        -0.150  0.000       \ncos365         0.065 -0.001 -0.151\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-3.19682240 -0.82387498 -0.07501834  0.63400484  5.82452468 \n\nNumber of Observations: 43820\nNumber of Groups: 20"
  },
  {
    "objectID": "qmd/500-multiple-areas-no-autocorrelation.html#residual-analysis",
    "href": "qmd/500-multiple-areas-no-autocorrelation.html#residual-analysis",
    "title": "5  Panel data: multiple areas without autocorrelation",
    "section": "5.5 Residual analysis",
    "text": "5.5 Residual analysis\nWe see that there is no evidence of autoregression in the residuals\n// STATA CODE STARTS\npac resid if fylke==1\n// STATA CODE ENDS\n\n# R CODE\npacf(residuals(fit1, type = \"normalized\")) # this is for AR\n\n\n\n\n\nWe see that there is no evidence of autoregression in the residuals\n// STATA CODE STARTS\nac resid if fylke==1\n// STATA CODE ENDS\n\n# R CODE\nacf(residuals(fit1, type = \"normalized\")) # this is for MA\n\n\n\n\n\nWe also obtain the same estimates that we did in the last chapter.\n\nb1 <- 1.4007640 # sin coefficient\nb2 <- -0.5234863 # cos coefficient\namplitude <- sqrt(b1^2 + b2^2)\np <- atan(b1/b2) * 365/2/pi\nif (p > 0) {\n    peak <- p\n    trough <- p + 365/2\n} else {\n    peak <- p + 365/2\n    trough <- p + 365\n}\nif (b1 < 0) {\n    g <- peak\n    peak <- trough\n    trough <- g\n}\nprint(sprintf(\"amplitude is estimated as %s, peak is estimated as %s, trough is estimated as %s\",round(amplitude,2),round(peak),round(trough)))\n\n[1] \"amplitude is estimated as 1.5, peak is estimated as 112, trough is estimated as 295\"\n\nprint(sprintf(\"true values are: amplitude: %s, peak: %s, trough: %s\",round(AMPLITUDE,2),round(365/4+SEASONAL_HORIZONTAL_SHIFT),round(3*365/4+SEASONAL_HORIZONTAL_SHIFT)))\n\n[1] \"true values are: amplitude: 1.5, peak: 111, trough: 294\""
  },
  {
    "objectID": "qmd/600-multiple-areas-with-autocorrelation.html#aim",
    "href": "qmd/600-multiple-areas-with-autocorrelation.html#aim",
    "title": "6  Panel data: multiple areas with autocorrelation",
    "section": "6.1 Aim",
    "text": "6.1 Aim\nWe are given a dataset containing daily counts of diseases from multiple geographical areas. We want to identify:\n\nDoes seasonality exist?\nIf seasonality exists, when are the high/low seasons?\nIs there a general yearly trend (i.e. increasing or decreasing from year to year?)"
  },
  {
    "objectID": "qmd/600-multiple-areas-with-autocorrelation.html#creating-the-data",
    "href": "qmd/600-multiple-areas-with-autocorrelation.html#creating-the-data",
    "title": "6  Panel data: multiple areas with autocorrelation",
    "section": "6.2 Creating the data",
    "text": "6.2 Creating the data\nThe data for this chapter is available at: https://www.csids.no/longitudinal-analysis-for-surveillance/data/chapter_7.csv\n\nlibrary(data.table)\nlibrary(ggplot2)\nset.seed(4)\n\nAMPLITUDE <- 1.5\nSEASONAL_HORIZONTAL_SHIFT <- 20\n\nfylkeIntercepts <- data.table(fylke=1:20,fylkeIntercepts=rnorm(20))\n\nd <- data.table(date=seq.Date(\n  from=as.Date(\"2010-01-01\"),\n  to=as.Date(\"2015-12-31\"),\n  by=1))\nd[,year:=as.numeric(format.Date(date,\"%G\"))]\nd[,week:=as.numeric(format.Date(date,\"%V\"))]\nd[,month:=as.numeric(format.Date(date,\"%m\"))]\n\ntemp <- vector(\"list\",length=20)\nfor(i in 1:20){\n  temp[[i]] <- copy(d)\n  temp[[i]][,fylke:=i]\n}\nd <- rbindlist(temp)\n\nd[,yearMinus2000:=year-2000]\nd[,dayOfSeries:=1:.N]\n\nd[,dayOfYear:=as.numeric(format.Date(date,\"%j\"))]\nd[,seasonalEffect:=sin(2*pi*(dayOfYear-SEASONAL_HORIZONTAL_SHIFT)/365)]\nd[,mu := round(exp(0.1 + yearMinus2000*0.1 + seasonalEffect*AMPLITUDE))]\nd[,y:=rpois(.N,mu)]\nd[,y:=mu+round(as.numeric(arima.sim(model=list(\"ar\"=c(0.5)), rand.gen = rpois, n=nrow(d), lambda=mu)))]"
  },
  {
    "objectID": "qmd/600-multiple-areas-with-autocorrelation.html#investigation",
    "href": "qmd/600-multiple-areas-with-autocorrelation.html#investigation",
    "title": "6  Panel data: multiple areas with autocorrelation",
    "section": "6.3 Investigation",
    "text": "6.3 Investigation\nWe drill down into a few years in fylke 1, and see a clear seasonal trend\n\nq <- ggplot(d[fylke==1],aes(x=dayOfYear,y=y))\nq <- q + facet_wrap(~year)\nq <- q + geom_point()\nq <- q + stat_smooth(colour=\"red\")\nq\n\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n\n\n\n\n\n\nThe Lomb-Scargle Periodogram shows a clear seasonality with a period of 365 days\n// STATA CODE STARTS\ninsheet using \"chapter_7.csv\", clear\n\nsort fylke date\nby fylke: gen time=_n\ntsset fylke time, daily\n\nwntestb y if fylke==1\n\ncumsp y if fylke==1, gen(cumulative_spec_dist)\nby fylke: gen period=_N/_n\n\nbrowse cumulative_spec_dist period\n// STATA CODE ENDS\n\n# R CODE\nlomb::lsp(d$y,from=100,to=500,ofac=1,type=\"period\")"
  },
  {
    "objectID": "qmd/600-multiple-areas-with-autocorrelation.html#regressions",
    "href": "qmd/600-multiple-areas-with-autocorrelation.html#regressions",
    "title": "6  Panel data: multiple areas with autocorrelation",
    "section": "6.4 Regressions",
    "text": "6.4 Regressions\nFirst we create an id variable. This generally corresponds to geographical locations, or people. In this case, we only have one geographical location, so our id for all observations is 1. This lets the computer know that all data belongs to the same group.\nWhen we have panel data with multiple areas, we use the MASS::glmPQL function in R and the meglm function in STATA. In R we identify the geographical areas with random = ~ § | fylke and in STATA with || fylke:.\n// STATA CODE STARTS\ngen cos365=cos(dayofyear*2*_pi/365)\ngen sin365=sin(dayofyear*2*_pi/365)\n\nmeglm y yearminus2000 || fylke:, family(poisson) iter(10)\nestimates store m1\nmeglm y yearminus2000 cos365 sin365 || fylke:, family(poisson) iter(10)\nestimates store m2\n\npredict resid, anscombe\n\nlrtest m1 m2\n// STATA CODE ENDS\n\n# R CODE\nd[,cos365:=cos(dayOfYear*2*pi/365)]\nd[,sin365:=sin(dayOfYear*2*pi/365)]\nfit0 <- MASS::glmmPQL(y~yearMinus2000, random = ~ 1 | fylke,\n                family = poisson, data = d)\n\niteration 1\n\nfit1 <- MASS::glmmPQL(y~yearMinus2000 + sin365 + cos365, random = ~ 1 | fylke,\n                family = poisson, data = d)\n\niteration 1\n\n\niteration 2\n\nprint(lmtest::lrtest(fit0, fit1))\n\nLikelihood ratio test\n\nModel 1: y ~ yearMinus2000\nModel 2: y ~ yearMinus2000 + sin365 + cos365\n  #Df LogLik Df Chisq Pr(>Chisq)\n1   4                           \n2   6         2                 \n\n\nWe see that the likelihood ratio test for sin365 and cos365 was significant, meaning that there is significant seasonality with a 365 day periodicity in our data (which we already strongly suspected due to the periodogram).\n\nWe can now run/look at the results of our main regression.\n\nprint(summary(fit1))\n\nLinear mixed-effects model fit by maximum likelihood\n  Data: d \n  AIC BIC logLik\n   NA  NA     NA\n\nRandom effects:\n Formula: ~1 | fylke\n        (Intercept)  Residual\nStdDev: 0.004579768 0.7191519\n\nVariance function:\n Structure: fixed weights\n Formula: ~invwt \nFixed effects:  y ~ yearMinus2000 + sin365 + cos365 \n                   Value   Std.Error    DF   t-value p-value\n(Intercept)    1.2189925 0.006110555 43797  199.4896       0\nyearMinus2000  0.0987374 0.000461394 43797  213.9980       0\nsin365         1.3990267 0.001531179 43797  913.6928       0\ncos365        -0.5171211 0.001282191 43797 -403.3106       0\n Correlation: \n              (Intr) yM2000 sin365\nyearMinus2000 -0.966              \nsin365        -0.147  0.000       \ncos365         0.065 -0.001 -0.152\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-3.00864057 -0.70228031 -0.06334676  0.64274011  5.21710224 \n\nNumber of Observations: 43820\nNumber of Groups: 20"
  },
  {
    "objectID": "qmd/600-multiple-areas-with-autocorrelation.html#residual-analysis",
    "href": "qmd/600-multiple-areas-with-autocorrelation.html#residual-analysis",
    "title": "6  Panel data: multiple areas with autocorrelation",
    "section": "6.5 Residual analysis",
    "text": "6.5 Residual analysis\nWe see that there is an AR(1) autocorrelation in the residuals, meaning that our model is not appropriate.\n// STATA CODE STARTS\npac resid if fylke==1\n// STATA CODE ENDS\n\n# R CODE\npacf(residuals(fit1, type = \"normalized\")) # this is for AR\n\n\n\n\n\nWe see that there is some sort of AR autocorrelation in the residuals, meaning that our model is not appropriate.\n// STATA CODE STARTS\nac resid if fylke==1\n// STATA CODE ENDS\n\n# R CODE\nacf(residuals(fit1, type = \"normalized\")) # this is for MA"
  },
  {
    "objectID": "qmd/600-multiple-areas-with-autocorrelation.html#r-only-regression-with-ar1-correlation-in-residuals",
    "href": "qmd/600-multiple-areas-with-autocorrelation.html#r-only-regression-with-ar1-correlation-in-residuals",
    "title": "6  Panel data: multiple areas with autocorrelation",
    "section": "6.6 (R ONLY) Regression with AR(1) correlation in residuals",
    "text": "6.6 (R ONLY) Regression with AR(1) correlation in residuals\nWe include correlation=nlme::corAR1(form=~dayOfSeries|fylke) or in other words correlation=nlme::corAR1(form=~time|group) to let the computer know what is the time variable and what is the group variable.\n\nfit1 <- MASS::glmmPQL(y~yearMinus2000+sin365 + cos365, random = ~ 1 | fylke,\n                family = poisson, data = d,\n                correlation=nlme::corAR1(form=~dayOfSeries|fylke))\n\niteration 1\n\nsummary(fit1)\n\nLinear mixed-effects model fit by maximum likelihood\n  Data: d \n  AIC BIC logLik\n   NA  NA     NA\n\nRandom effects:\n Formula: ~1 | fylke\n         (Intercept)  Residual\nStdDev: 2.405145e-05 0.7195239\n\nCorrelation Structure: AR(1)\n Formula: ~dayOfSeries | fylke \n Parameter estimate(s):\n      Phi \n0.5240054 \nVariance function:\n Structure: fixed weights\n Formula: ~invwt \nFixed effects:  y ~ yearMinus2000 + sin365 + cos365 \n                   Value   Std.Error    DF   t-value p-value\n(Intercept)    1.2195477 0.010774796 43797  113.1852       0\nyearMinus2000  0.0987065 0.000825226 43797  119.6115       0\nsin365         1.3988945 0.002739109 43797  510.7116       0\ncos365        -0.5169579 0.002292465 43797 -225.5030       0\n Correlation: \n              (Intr) yM2000 sin365\nyearMinus2000 -0.979              \nsin365        -0.149  0.001       \ncos365         0.066 -0.001 -0.151\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-2.99731654 -0.70249782 -0.06736726  0.64264790  5.20296607 \n\nNumber of Observations: 43820\nNumber of Groups: 20"
  },
  {
    "objectID": "qmd/600-multiple-areas-with-autocorrelation.html#residual-analysis-1",
    "href": "qmd/600-multiple-areas-with-autocorrelation.html#residual-analysis-1",
    "title": "6  Panel data: multiple areas with autocorrelation",
    "section": "6.7 Residual analysis",
    "text": "6.7 Residual analysis\nWe see that the vast majority of the autoregression in the residuals has been removed.\n\npacf(residuals(fit1, type = \"normalized\")) # this is for AR\n\n\n\n\n\nWe see that the vast majority of the autoregression in the residuals has been removed.\n\nacf(residuals(fit1, type = \"normalized\")) # this is for MA\n\n\n\n\n\nWe obtain the same estimates that we did in the last chapter.\n\nb1 <- 1.4007640 # sin coefficient\nb2 <- -0.5234863 # cos coefficient\namplitude <- sqrt(b1^2 + b2^2)\np <- atan(b1/b2) * 365/2/pi\nif (p > 0) {\n    peak <- p\n    trough <- p + 365/2\n} else {\n    peak <- p + 365/2\n    trough <- p + 365\n}\nif (b1 < 0) {\n    g <- peak\n    peak <- trough\n    trough <- g\n}\nprint(sprintf(\"amplitude is estimated as %s, peak is estimated as %s, trough is estimated as %s\",round(amplitude,2),round(peak),round(trough)))\n\n[1] \"amplitude is estimated as 1.5, peak is estimated as 112, trough is estimated as 295\"\n\nprint(sprintf(\"true values are: amplitude: %s, peak: %s, trough: %s\",round(AMPLITUDE,2),round(365/4+SEASONAL_HORIZONTAL_SHIFT),round(3*365/4+SEASONAL_HORIZONTAL_SHIFT)))\n\n[1] \"true values are: amplitude: 1.5, peak: 111, trough: 294\""
  },
  {
    "objectID": "qmd/600-multiple-areas-with-autocorrelation.html#stata-only-regression-with-robust-standard-errors",
    "href": "qmd/600-multiple-areas-with-autocorrelation.html#stata-only-regression-with-robust-standard-errors",
    "title": "6  Panel data: multiple areas with autocorrelation",
    "section": "6.8 (STATA ONLY) Regression with robust standard errors",
    "text": "6.8 (STATA ONLY) Regression with robust standard errors\nIn STATA it is not possible to explicitly model autocorrelation in the residuals (with the exception of linear regression). Since most of our work deals with logistic and poisson regressions, we will be focusing on modelling strategies that work with all kinds of regressions.\nThe STATA approach to autocorrelation is to estimate more robust standard errors. That is, STATA makes the standard errors larger to account for the model mispecification. This is done through the vce(robust) option.\n// STATA CODE STARTS\nmeglm y yearminus2000 cos365 sin365 || fylke:, family(poisson) iter(10) vce(robust)\n// STATA CODE ENDS"
  },
  {
    "objectID": "qmd/700-exercises.html#exercise-1",
    "href": "qmd/700-exercises.html#exercise-1",
    "title": "7  Exercises",
    "section": "7.1 Exercise 1",
    "text": "7.1 Exercise 1\nWe are given a dataset containing daily counts of diseases y from one geographical area. We want to identify:\n\nIs there a general yearly trend (i.e. increasing or decreasing from year to year?)\nDoes seasonality exist (use the categorical variable “season”)?\nWhat season has the most cases? (Spring/summer/autumn/winter?)\nIs numberOfCows associated with the outcome y?\n\nThe data for this chapter is available at: https://www.csids.no/longitudinal-analysis-for-surveillance/data/exercise_1.csv\n\nlibrary(data.table)\nset.seed(4)\n\nd <- data.table(date=seq.Date(\n  from=as.Date(\"2010-01-01\"),\n  to=as.Date(\"2015-12-31\"),\n  by=1))\n\nd[,numberOfCows:=rpois(.N,5)]\n\nd[,year:=as.numeric(format.Date(date,\"%G\"))]\nd[,week:=as.numeric(format.Date(date,\"%V\"))]\nd[,month:=as.numeric(format.Date(date,\"%m\"))]\nd[,season:=\"Winter\"]\nd[month %in% c(3:5), season:=\"Spring\"]\nd[month %in% c(6:8), season:=\"Summer\"]\nd[month %in% c(9:11), season:=\"Autumn\"]\n\nd[,seasonIntercept:=0]\nd[season==\"Spring\",seasonIntercept:=1]\nd[season==\"Summer\",seasonIntercept:=2]\n\nd[,yearMinus2000:=year-2000]\nd[,dayOfSeries:=1:.N]\n\nd[,mu := round(exp(0.1 + yearMinus2000*0.2 + seasonIntercept + 0.2*numberOfCows))]\nd[,y:=rpois(.N,mu)]"
  },
  {
    "objectID": "qmd/700-exercises.html#exercise-2",
    "href": "qmd/700-exercises.html#exercise-2",
    "title": "7  Exercises",
    "section": "7.2 Exercise 2",
    "text": "7.2 Exercise 2\nWe are given a dataset containing daily counts of diseases y from three geographical areas (fylke). We want to identify:\n\nIs there a general yearly trend (i.e. increasing or decreasing from year to year?)\nDoes seasonality exist (use the categorical variable “season”)?\nWhat season has the most cases? (Spring/summer/autumn/winter?)\nIs numberOfCows associated with the outcome y?\n\nThe data for this chapter is available at: https://www.csids.no/longitudinal-analysis-for-surveillance/data/exercise_2.csv\n\nlibrary(data.table)\nset.seed(4)\n\nd <- data.table(date=seq.Date(\n  from=as.Date(\"2010-01-01\"),\n  to=as.Date(\"2015-12-31\"),\n  by=1))\n\ntemp <- vector(\"list\",length=3)\nfor(i in 1:3){\n  temp[[i]] <- copy(d)\n  temp[[i]][,fylke:=i]\n}\nd <- rbindlist(temp)\n\nd[,numberOfCows:=rpois(.N,5)]\n\nd[,year:=as.numeric(format.Date(date,\"%G\"))]\nd[,week:=as.numeric(format.Date(date,\"%V\"))]\nd[,month:=as.numeric(format.Date(date,\"%m\"))]\nd[,season:=\"Winter\"]\nd[month %in% c(3:5), season:=\"Spring\"]\nd[month %in% c(6:8), season:=\"Summer\"]\nd[month %in% c(9:11), season:=\"Autumn\"]\n\nd[,seasonIntercept:=0]\nd[season==\"Spring\",seasonIntercept:=1]\nd[season==\"Summer\",seasonIntercept:=2]\n\nd[,yearMinus2000:=year-2000]\nd[,dayOfSeries:=1:.N,by=fylke]\n\nd[,mu := round(exp(0.1 + yearMinus2000*0.2 + seasonIntercept + 0.0*numberOfCows + 0.1*(fylke-2)))]\nd[,y:=rpois(.N,mu)]\nfor(i in 1:3) d[fylke==i,y:=round(as.numeric(arima.sim(model=list(\"ar\"=c(0.5)), rand.gen = rpois, n=.N, lambda=mu)))]"
  },
  {
    "objectID": "qmd/700-exercises.html#exercise-3",
    "href": "qmd/700-exercises.html#exercise-3",
    "title": "7  Exercises",
    "section": "7.3 Exercise 3",
    "text": "7.3 Exercise 3\nWe are given a dataset containing counts of diseases y from three geographical areas (fylke). We want to identify:\n\nIs there a general yearly trend (i.e. increasing or decreasing from year to year?)\nDoes seasonality exist (use the categorical variable “season”)?\nWhat season has the most cases? (Spring/summer/autumn/winter?)\nIs numberOfCows associated with the outcome y?\n\nThe data for this chapter is available at: https://www.csids.no/longitudinal-analysis-for-surveillance/data/exercise_3.csv\n\nlibrary(data.table)\nset.seed(4)\n\nd <- data.table(date=seq.Date(\n  from=as.Date(\"2010-01-01\"),\n  to=as.Date(\"2015-12-31\"),\n  by=1))\n\ntemp <- vector(\"list\",length=3)\nfor(i in 1:3){\n  temp[[i]] <- copy(d)\n  temp[[i]][,fylke:=i]\n}\nd <- rbindlist(temp)\n\nd[,numberOfCows:=rpois(.N,5)]\n\nd[,year:=as.numeric(format.Date(date,\"%G\"))]\nd[,week:=as.numeric(format.Date(date,\"%V\"))]\nd[,month:=as.numeric(format.Date(date,\"%m\"))]\nd[,season:=\"Winter\"]\nd[month %in% c(3:5), season:=\"Spring\"]\nd[month %in% c(6:8), season:=\"Summer\"]\nd[month %in% c(9:11), season:=\"Autumn\"]\n\nd[,seasonIntercept:=0]\nd[season==\"Spring\",seasonIntercept:=1]\nd[season==\"Summer\",seasonIntercept:=2]\n\nd[,yearMinus2000:=year-2000]\n\nd <- d[sample(1:.N,600)]\n\nd[,mu := round(exp(0.1 + yearMinus2000*0.2 + seasonIntercept + 0.0*numberOfCows + 0.1*(fylke-2)))]\nd[,y:=rpois(.N,mu)]"
  },
  {
    "objectID": "qmd/800-solutions.html#exercise-1",
    "href": "qmd/800-solutions.html#exercise-1",
    "title": "8  Solutions",
    "section": "8.1 Exercise 1",
    "text": "8.1 Exercise 1\n\nlibrary(data.table)\nd <- fread(\"data/exercise_1.csv\")\n\nfit0 <- glm(y ~ yearMinus2000 + numberOfCows, data=d, family=poisson())\nfit1 <- glm(y ~ season + yearMinus2000 + numberOfCows, data=d, family=poisson())\n\nprint(lmtest::lrtest(fit0, fit1))\n\nLikelihood ratio test\n\nModel 1: y ~ yearMinus2000 + numberOfCows\nModel 2: y ~ season + yearMinus2000 + numberOfCows\n  #Df  LogLik Df  Chisq Pr(>Chisq)    \n1   3 -104814                         \n2   6   -7847  3 193933  < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(fit1)\n\n\nCall:\nglm(formula = y ~ season + yearMinus2000 + numberOfCows, family = poisson(), \n    data = d)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-3.5547  -0.6743  -0.0203   0.6393   3.2527  \n\nCoefficients:\n                Estimate Std. Error z value Pr(>|z|)    \n(Intercept)    0.0998769  0.0168980   5.911 3.41e-09 ***\nseasonSpring   0.9996116  0.0077048 129.739  < 2e-16 ***\nseasonSummer   2.0061609  0.0070148 285.990  < 2e-16 ***\nseasonWinter  -0.0048955  0.0093124  -0.526    0.599    \nyearMinus2000  0.2001843  0.0011420 175.298  < 2e-16 ***\nnumberOfCows   0.1987005  0.0007667 259.153  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 296600.3  on 2190  degrees of freedom\nResidual deviance:   2167.4  on 2185  degrees of freedom\nAIC: 15707\n\nNumber of Fisher Scoring iterations: 4\n\nd[,residuals:=residuals(fit1, type = \"response\")]\n\npacf(d$residuals)\n\n\n\nacf(d$residuals)"
  },
  {
    "objectID": "qmd/800-solutions.html#exercise-2",
    "href": "qmd/800-solutions.html#exercise-2",
    "title": "8  Solutions",
    "section": "8.2 Exercise 2",
    "text": "8.2 Exercise 2\n\nlibrary(data.table)\nd <- fread(\"data/exercise_2.csv\")\n\nfit0 <- MASS::glmmPQL(y~yearMinus2000 + numberOfCows, random = ~ 1 | fylke,\n                family = poisson, data = d)\n\niteration 1\n\n\niteration 2\n\nfit1 <- MASS::glmmPQL(y~season + yearMinus2000 + numberOfCows, random = ~ 1 | fylke,\n                family = poisson, data = d)\n\niteration 1\niteration 2\n\n\niteration 3\n\nprint(lmtest::lrtest(fit0, fit1))\n\nLikelihood ratio test\n\nModel 1: y ~ yearMinus2000 + numberOfCows\nModel 2: y ~ season + yearMinus2000 + numberOfCows\n  #Df LogLik Df Chisq Pr(>Chisq)\n1   5                           \n2   8         3                 \n\nsummary(fit1)\n\nLinear mixed-effects model fit by maximum likelihood\n  Data: d \n  AIC BIC logLik\n   NA  NA     NA\n\nRandom effects:\n Formula: ~1 | fylke\n        (Intercept) Residual\nStdDev:  0.08342256 1.298934\n\nVariance function:\n Structure: fixed weights\n Formula: ~invwt \nFixed effects:  y ~ season + yearMinus2000 + numberOfCows \n                   Value  Std.Error   DF   t-value p-value\n(Intercept)    0.8483946 0.05053613 6565  16.78788  0.0000\nseasonSpring   0.9334080 0.00685147 6565 136.23480  0.0000\nseasonSummer   1.9312703 0.00621739 6565 310.62400  0.0000\nseasonWinter  -0.0822382 0.00841368 6565  -9.77434  0.0000\nyearMinus2000  0.2004222 0.00104237 6565 192.27503  0.0000\nnumberOfCows   0.0005788 0.00077223 6565   0.74954  0.4536\n Correlation: \n              (Intr) ssnSpr ssnSmm ssnWnt yM2000\nseasonSpring  -0.097                            \nseasonSummer  -0.106  0.793                     \nseasonWinter  -0.079  0.586  0.646              \nyearMinus2000 -0.268  0.000  0.000 -0.002       \nnumberOfCows  -0.070 -0.002 -0.018  0.004 -0.020\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-5.44473503 -0.49365704 -0.05256441  0.39697143 16.32534219 \n\nNumber of Observations: 6573\nNumber of Groups: 3 \n\nd[,residuals:=residuals(fit1, type = \"normalized\")]\n\npacf(d$residuals)\n\n\n\nacf(d$residuals)\n\n\n\nfit1 <- MASS::glmmPQL(y~season + yearMinus2000 + numberOfCows, random = ~ 1 | fylke,\n                family = poisson, data = d,\n                correlation=nlme::corAR1(form=~dayOfSeries|fylke))\n\niteration 1\n\n\niteration 2\n\n\niteration 3\n\nsummary(fit1)\n\nLinear mixed-effects model fit by maximum likelihood\n  Data: d \n  AIC BIC logLik\n   NA  NA     NA\n\nRandom effects:\n Formula: ~1 | fylke\n        (Intercept) Residual\nStdDev:  0.08328798 1.319938\n\nCorrelation Structure: AR(1)\n Formula: ~dayOfSeries | fylke \n Parameter estimate(s):\n      Phi \n0.5525116 \nVariance function:\n Structure: fixed weights\n Formula: ~invwt \nFixed effects:  y ~ season + yearMinus2000 + numberOfCows \n                   Value  Std.Error   DF   t-value p-value\n(Intercept)    0.9283222 0.05561940 6565  16.69062   0.000\nseasonSpring   0.8631442 0.01224757 6565  70.47476   0.000\nseasonSummer   1.8166993 0.01098229 6565 165.42086   0.000\nseasonWinter  -0.1394364 0.01488823 6565  -9.36554   0.000\nyearMinus2000  0.2001812 0.00197415 6565 101.40142   0.000\nnumberOfCows   0.0004206 0.00057695 6565   0.72909   0.466\n Correlation: \n              (Intr) ssnSpr ssnSmm ssnWnt yM2000\nseasonSpring  -0.155                            \nseasonSummer  -0.171  0.784                     \nseasonWinter  -0.123  0.574  0.621              \nyearMinus2000 -0.464  0.000  0.000 -0.002       \nnumberOfCows  -0.049  0.001 -0.006  0.004 -0.007\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-5.03056012 -0.54478730 -0.04721577  0.46011628 15.05853958 \n\nNumber of Observations: 6573\nNumber of Groups: 3 \n\nd[,residuals:=residuals(fit1, type = \"normalized\")]\n\npacf(d$residuals)\n\n\n\nacf(d$residuals)"
  },
  {
    "objectID": "qmd/800-solutions.html#exercise-3",
    "href": "qmd/800-solutions.html#exercise-3",
    "title": "8  Solutions",
    "section": "8.3 Exercise 3",
    "text": "8.3 Exercise 3\n\nlibrary(data.table)\nd <- fread(\"data/exercise_3.csv\")\n\nfit0 <- lme4::glmer(y ~ yearMinus2000 + numberOfCows + (1|fylke), family = poisson, data = d)\nfit1 <- lme4::glmer(y ~ season + yearMinus2000 + numberOfCows + (1|fylke), family = poisson, data = d)\n\nprint(lmtest::lrtest(fit0, fit1))\n\nLikelihood ratio test\n\nModel 1: y ~ yearMinus2000 + numberOfCows + (1 | fylke)\nModel 2: y ~ season + yearMinus2000 + numberOfCows + (1 | fylke)\n  #Df   LogLik Df Chisq Pr(>Chisq)    \n1   4 -10402.8                        \n2   7  -1830.9  3 17144  < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(fit1)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: poisson  ( log )\nFormula: y ~ season + yearMinus2000 + numberOfCows + (1 | fylke)\n   Data: d\n\n     AIC      BIC   logLik deviance df.resid \n  3675.9   3706.7  -1830.9   3661.9      593 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.3420 -0.6168  0.0094  0.5807  3.4186 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n fylke  (Intercept) 0.006123 0.07825 \nNumber of obs: 600, groups:  fylke, 3\n\nFixed effects:\n               Estimate Std. Error z value Pr(>|z|)    \n(Intercept)    0.110463   0.071421   1.547    0.122    \nseasonSpring   1.005705   0.024761  40.617   <2e-16 ***\nseasonSummer   1.995156   0.022578  88.367   <2e-16 ***\nseasonWinter  -0.010649   0.030097  -0.354    0.723    \nyearMinus2000  0.197456   0.003717  53.118   <2e-16 ***\nnumberOfCows   0.004522   0.002834   1.595    0.111    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) ssnSpr ssnSmm ssnWnt yM2000\nseasonSprng -0.276                            \nseasonSummr -0.294  0.792                     \nseasonWintr -0.244  0.595  0.652              \nyearMns2000 -0.687  0.030  0.030  0.044       \nnumberOfCws -0.193  0.026 -0.002  0.040 -0.015"
  }
]